defaultpenalty() = :l1
defaultseg() = 5

"""
    convex_linearization(x, z, optimizer; kwargs...)

Computes a piecewise linear function that approximates the measurements given by `x` and `z`.

# Arguments
- `method::Symbol:=fit`: the method used for approximation
- `nseg::Integer=5`: the number of segments to use 
- `pen::Symbol=:l1`: the metric used to measure deviation
"""
function convex_linearization(x::Vector, z::Vector, optimizer; kwargs...)
    @assert(length(x) == length(z))

    defaults = (;method=:fit)
    options = merge(defaults, kwargs)

    method = options.method

    if method == :fit
        return convex_linearization_fit(x, z, optimizer; kwargs...)
    elseif method == :ipol
        return convex_linearization_ipol(x, z, optimizer; kwargs...)
    else
        error("Unrecognized method $method")
    end
end

convex_linearization(x, z, optimizer; kwargs...)  = 
    convex_linearization([xx for xx in x], [zz for zz in z], optimizer; kwargs...)

function convex_linearization_fit(x::Vector, z::Vector, optimizer; kwargs...)
  
    defaults = (nseg=defaultseg(), pen=defaultpenalty(), strict=false, start_origin=false, show_res=false)
    options = merge(defaults, kwargs)
  
    N = length(x)
    ­ЮњЕ = 1:N 
    ­Юњд = 1:options.nseg
    
    cрхЅ╦брхЌ = (z[N] -z[N-1])/(x[N]-x[N-1])
    MрхЄРЂ▒рхЇ =  2 * cрхЅ╦брхЌ * (last(x) - first(x)) - maximum(z)
    
    m = JuMP.Model()
    ­ЮЉД╠ѓ = JuMP.@variable(m, [­ЮњЕ]) 
    ­ЮЉљ = JuMP.@variable(m, [­Юњд])
    ­ЮЉЉ = JuMP.@variable(m, [­Юњд]) 
    ­ЮЉб = JuMP.@variable(m, [­ЮњЕ,­Юњд], Bin)

    if options.pen == :l2 
        JuMP.@objective(m, Min, sum((z[i] - ­ЮЉД╠ѓ[i])^2 for i Рѕѕ ­ЮњЕ))
    elseif options.pen == :max
        ­ЮЉА = JuMP.@variable(m)
        JuMP.@objective(m, Min, ­ЮЉА)
        for i Рѕѕ ­ЮњЕ
            JuMP.@constraint(m,  ­ЮЉА РЅЦ (z[i] - ­ЮЉД╠ѓ[i]) )
            JuMP.@constraint(m,  ­ЮЉА РЅЦ (­ЮЉД╠ѓ[i] - z[i]) )
        end
    elseif options.pen == :l1
        ­ЮЉА = JuMP.@variable(m, [­ЮњЕ])
        JuMP.@objective(m, Min, sum(­ЮЉА))
        for i Рѕѕ ­ЮњЕ
            JuMP.@constraint(m,  ­ЮЉА[i] РЅЦ (z[i] - ­ЮЉД╠ѓ[i]) )
            JuMP.@constraint(m,  ­ЮЉА[i] РЅЦ (­ЮЉД╠ѓ[i] - z[i]) )
        end
    else
        error("Unrecognized/unsupported penalty type $(options.pen)")
    end

    for i Рѕѕ ­ЮњЕ, k Рѕѕ ­Юњд 
        JuMP.@constraint(m, ­ЮЉД╠ѓ[i] РЅЦ ­ЮЉљ[k] * x[i] + ­ЮЉЉ[k])
        JuMP.@constraint(m, ­ЮЉД╠ѓ[i] РЅц ­ЮЉљ[k] * x[i] + ­ЮЉЉ[k] + MрхЄРЂ▒рхЇ * (1-­ЮЉб[i,k]))
    end

    if options.strict
        for i Рѕѕ ­ЮњЕ, k Рѕѕ ­Юњд 
            JuMP.@constraint(m, z[i] РЅЦ ­ЮЉљ[k] * x[i] + ­ЮЉЉ[k])   
        end
    end

    if options.start_origin
        JuMP.@constraint(m,­ЮЉЉ[1] == 0.0)
    end

    for i Рѕѕ ­ЮњЕ
        JuMP.@constraint(m, sum(­ЮЉб[i,k] for k Рѕѕ ­Юњд) РЅЦ 1)
    end

    for k Рѕѕ ­Юњд 
        if k > 1
            JuMP.@constraint(m, ­ЮЉљ[k-1] РЅц ­ЮЉљ[k])
        end
    end


    JuMP.set_optimizer(m,optimizer)
    JuMP.optimize!(m)

    if JuMP.termination_status(m) != MOI.OPTIMAL
        error("Optimization failed")
    end

    if options.show_res
        println("Optimize succeed for $(options.pen)")
        val = JuMP.objective_value(m)
        println("Objective value = $val")
    end
    
    ­ЮЉљр┤╝рхќрхЌ = JuMP.value.(­ЮЉљ)
    ­ЮЉЉр┤╝рхќрхЌ = JuMP.value.(­ЮЉЉ) 

    return ConvexPWLFunction([­ЮЉљр┤╝рхќрхЌ[k] for k Рѕѕ ­Юњд], [­ЮЉЉр┤╝рхќрхЌ[k] for k Рѕѕ ­Юњд], minimum(x), maximum(x))
end

function convex_linearization(f::Function, xmin, xmax, optimizer; kwargs...)
    @assert(xmin < xmax)

    defaults = (nsample=10, nseg=defaultseg()) 
    options = merge(defaults, kwargs)

    samples = max(options.nsample, 3*options.nseg)

    step = (xmax - xmin) / samples
    x = [i for i in xmin:step:xmax]
    y = [f(xx) for xx in x]
    return convex_linearization(x, y, optimizer; kwargs...)
end

function concave_linearization(x, z, optimizer; kwargs...)
    return ConcavePWLFunction(convex_linearization(x, -z, optimizer; kwargs...))
end

function concave_linearization(f::Function, xmin, xmax, optimizer; kwargs...)
    return ConcavePWLFunction(convex_linearization(x -> -f(x), xmin, xmax, optimizer; kwargs...))
end


function convexify(pwl::PWLFunction, optimizer)
    N = length(pwl.x)
    ­ЮњЕ = 1: N
    x = pwl.x
    z = pwl.z

    m = Model()

    ╬┤РЂ║ = @variable(m, [­ЮњЕ], lower_bound=0)
    ╬┤РЂ╗ = @variable(m, [­ЮњЕ], lower_bound=0)

    @objective(m, Min, sum(╬┤РЂ║[i] + ╬┤РЂ╗[i] for i Рѕѕ ­ЮњЕ))
    for i=2:N-1
        @constraint(m, (z[i] + ╬┤РЂ║[i] - ╬┤РЂ╗[i] - z[i-1] - ╬┤РЂ║[i-1] + ╬┤РЂ╗[i-1]) / 
            (x[i] -x[i-1]) <= (z[i+1] + ╬┤РЂ║[i+1] - ╬┤РЂ╗[i+1] - z[i] - ╬┤РЂ║[i] + ╬┤РЂ╗[i]) / (x[i+1] -x[i]))
    end

    set_optimizer(m,optimizer)
    optimize!(m)
    if termination_status(m) != MOI.OPTIMAL
        error("Optimization failed")
    end

    dp = value.(╬┤РЂ║)
    dn = value.(╬┤РЂ╗)

    return ConvexPWLFunction(x, [z[i] + dp[i] - dn[i] for i Рѕѕ ­ЮњЕ]) 
end

convexify(x, z, optimizer) =
    convexify(PWLFunction(x,z), optimizer)

function interpolatepw(x, z, optimizer; kwargs...)
    @assert(length(x) == length(z))

    defaults = (nseg=defaultseg(), pen=defaultpenalty())
    options = merge(defaults, kwargs)
   
    N = length(x)
    ­ЮњЕ = 1:N 

    # Find slopes
    c = [(z[j] -z[i]) / (x[j]-x[i])  for i Рѕѕ ­ЮњЕ, j Рѕѕ ­ЮњЕ]

    # Calculate penalties 
    if options.pen == :l1
        p = [(i < j ? sum(abs(c[i,j] * (x[k] - x[i]) + z[i] - z[k]) for k Рѕѕ i:j) : 0) for i Рѕѕ ­ЮњЕ, j Рѕѕ ­ЮњЕ]
    elseif options.pen == :l2
        p = [(i < j ? sum((c[i,j] * (x[k] - x[i]) + z[i] - z[k])^2 for k Рѕѕ i:j) : 0) for i Рѕѕ ­ЮњЕ, j Рѕѕ ­ЮњЕ]
    elseif options.pen == :max
        p = [(i < j ? maximum(abs(c[i,j] * (x[k] - x[i]) + z[i] - z[k]) for k Рѕѕ i:j) : 0) for i Рѕѕ ­ЮњЕ, j Рѕѕ ­ЮњЕ]
    else
        error("Unrecognized/unsupported penalty $(options.pen)")
    end
    
    m = Model()
    @variable(m, ­ЮЉб[­ЮњЕ,­ЮњЕ], Bin)

    # Minimize total penalty
    @objective(m, Min, sum(p[i,j] * ­ЮЉб[i,j] for i Рѕѕ ­ЮњЕ, j Рѕѕ ­ЮњЕ))

    # Number of line segments in interpolant
    @constraint(m, sum(­ЮЉб[i,j] for i Рѕѕ ­ЮњЕ, j Рѕѕ ­ЮњЕ) == options.nseg )

    # Only forward segments allowed
    for i Рѕѕ ­ЮњЕ, j Рѕѕ ­ЮњЕ 
        if i >= j 
            @constraint(m, ­ЮЉб[i,j] == 0)
        end
    end 

    # Path modelling
    for j Рѕѕ ­ЮњЕ
        @constraint(m, (j > 1 ? sum(­ЮЉб[i,j] for i Рѕѕ ­ЮњЕ) : 1) == (j < N ? sum(­ЮЉб[j,i] for i Рѕѕ ­ЮњЕ ) : 1))
    end

    set_optimizer(m,optimizer)
    optimize!(m)
    if termination_status(m) != MOI.OPTIMAL
        error("Optimization failed")
    end
    
    ­ЮЉбр┤╝рхќрхЌ = value.(m[:­ЮЉб])
    xр┤╝рхќрхЌ = collect(x[i] for i Рѕѕ ­ЮњЕ, j Рѕѕ ­ЮњЕ if ­ЮЉбр┤╝рхќрхЌ[i,j] == 1)
    push!(xр┤╝рхќрхЌ, x[N])
    zр┤╝рхќрхЌ = collect(z[i] for i Рѕѕ ­ЮњЕ, j Рѕѕ ­ЮњЕ if ­ЮЉбр┤╝рхќрхЌ[i,j] == 1)
    push!(zр┤╝рхќрхЌ, z[N])

    return PWLFunction(xр┤╝рхќрхЌ, zр┤╝рхќрхЌ)
end

convex_linearization_ipol(x, z, optimizer; kwargs...) = 
    convexify(interpolatepw(x, z, optimizer; kwargs...),optimizer)
