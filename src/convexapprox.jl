defaultpenalty() = :l1
defaultpenalty2D() = :l2
defaultseg() = 5
defaultplanes() = 4

#= 
    Start new typed interface here
=#
"""
    approx(input::FunctionEvaluations{D}, c::Curvature, a::Algorithm; kwargs...)

Return ConvexPWLFunc{D} or ConcavePWLFunc{D} depending on `c`, approximating the `input` points in `D` dimensions

Accepted keyword arguments currently include:
- `optimizer`: JuMP Optimizer
- `nplanes`: number of (hyper)planes to use for approximation
- `strict`: (TODO: Better name?) `strict âˆˆ (:none, :over, :under)`
- `pen:l1`:  the metric used to measure deviation `pen âˆˆ (:l1,:l2)`
"""
function approx(input, c::Concave, a ; kwargs...)
    cv = approx(FunctionEvaluations(input.points,-input.values),Convex(),a; kwargs...)
    # TODO: Generalize on D (hard coded to 2 for now)
    return PWLFunc{Concave,dims(cv)}(cv.planes)
end
dims(pwl::PWLFunc{C,D}) where {C,D} = D
concave(pwl::PWLFunc{C,D}) where {C<:Convex,D} = PWLFunc(pwl.planes,Concave())
# Using dispatch for specializing on dimensions. If performance were a concern,
# maybe just do branching and call specialized function directly
approx(input::FunctionEvaluations{D}, c::Convex, a ; kwargs...) where D = approx(input, c, a, Val(D); kwargs...)
# Specialized for 1D
function approx(input::FunctionEvaluations{D}, c::Convex, a::Interpol, ::Val{1} ; kwargs...) where D
    defaults = (nsegs=defaultseg(), nplanes=defaultplanes(), pen=defaultpenalty2D(), strict=:none, show_res=false)
    options = merge(defaults, kwargs)
    # Wrap for now, TODO: move here
    convex_linearization_ipol([i[1] for i in input.points], input.values, options.optimizer; kwargs...)
end

function approx(input::FunctionEvaluations{D}, c::Convex, a::Optimized, ::Val{1} ; kwargs...) where D
    defaults = (nsegs=defaultseg(), nplanes=defaultplanes(), pen=defaultpenalty2D(), strict=:none, show_res=false)
    options = merge(defaults, kwargs)
    # Wrap until big M issue is solved generally
    # TODO: move here
    convex_linearization_fit([i[1] for i in input.points], input.values, options.optimizer; kwargs...)
end

# Heuristic for general dimension
function approx(input::FunctionEvaluations{D}, c::Convex, a::Heuristic; kwargs...) where D
    x = [p[i] for i in 1:D, p in input.points] 
    z = input.values
    return convex_linearization_mb(x, z; kwargs...) 
end

# General D
function approx(input::FunctionEvaluations{D}, c::Convex, a::Optimized, dims ; kwargs...) where D
    defaults = (nsegs=defaultseg(), nplanes=defaultplanes(), pen=defaultpenalty2D(), strict=:none, show_res=false)
    options = merge(defaults, kwargs)

    ğ’« = input.points
    z = input.values
    záµ– = Dict(zip(ğ’«, z))
    ğ’¦ = 1:options.nplanes
    â„â‚š = 1:length(ğ’«[1])    

    Máµ‡â±áµ = linear_big_M(ğ’«, z) 

    m = Model()
    @variable(m, ğ‘§Ì‚[ğ’«])
    @variable(m, a[â„â‚š, ğ’¦])
    @variable(m, b[ğ’¦])

    @variable(m, ğ‘¢[ğ’«, ğ’¦], Bin)

    if options.pen == :l2 
        @objective(m, Min, sum((záµ–[p] - ğ‘§Ì‚[p])^2 for p âˆˆ ğ’«))
    elseif options.pen == :max
        ğ‘¡ = @variable(m)
        @objective(m, Min, ğ‘¡)
        for p âˆˆ ğ’«
            @constraint(m,  ğ‘¡ â‰¥ (záµ–[p] - ğ‘§Ì‚[p]) )
            @constraint(m,  ğ‘¡ â‰¥ (ğ‘§Ì‚[p] - záµ–[p]) )
        end
    elseif options.pen == :l1
        ğ‘¡ = @variable(m, [ğ’«])
        @objective(m, Min, sum(ğ‘¡))
        for p âˆˆ ğ’«
            @constraint(m,  ğ‘¡[p] â‰¥ (záµ–[p] - ğ‘§Ì‚[p]) )
            @constraint(m,  ğ‘¡[p] â‰¥ (ğ‘§Ì‚[p] - záµ–[p]) )
        end
    else
        error("Unrecognized/unsupported penalty type $(options.pen)")
    end
     
    for p âˆˆ ğ’«, k âˆˆ ğ’¦         
        @constraint(m, ğ‘§Ì‚[p] â‰¥ sum(a[j,k] * p[j] for j in â„â‚š) + b[k])
        @constraint(m, ğ‘§Ì‚[p] â‰¤ sum(a[j,k] * p[j] for j in â„â‚š) + b[k] + Máµ‡â±áµ * (1-ğ‘¢[p,k]))                
    end

    if options.strict == :above
        for p âˆˆ ğ’«, k âˆˆ ğ’¦ 
            @constraint(m, záµ–[p] â‰¥ sum(a[j,k] * p[j] for j in â„â‚š) + b[k]) 
        end
    elseif options.strict == :below
        for p âˆˆ ğ’«, k âˆˆ ğ’¦ 
            @constraint(m, záµ–[p] â‰¤ sum(a[j,k] * p[j] for j in â„â‚š) + b[k]) 
        end
    end
    
    for p âˆˆ ğ’«
        @constraint(m, sum(ğ‘¢[p,k] for k âˆˆ ğ’¦) â‰¥ 1)
    end    
    
    set_optimizer(m,options.optimizer)
    optimize!(m)

    if termination_status(m) != MOI.OPTIMAL
        error("Optimization failed")
    end

    if options.show_res
        println("Optimize succeed for $(options.pen)")
        val = objective_value(m)
        println("Objective value = $val")
    end   
    
    aá´¼áµ–áµ— = value.(a)
    bá´¼áµ–áµ— = value.(b)    
    
    return PWLFunc{Convex,D}([Plane(Tuple(aá´¼áµ–áµ—.data[:,k]), bá´¼áµ–áµ—[k]) for k âˆˆ ğ’¦])
end

# Sample the function on a uniform grid within the given bounding box using nsamples in each dimension
function sample_uniform(f::Function, bbox::Vector{<:Tuple}, nsamples)
    it = Iterators.product((LinRange(bbox[d][1], bbox[d][2], nsamples) for d in 1:length(bbox))...)
    x = vec(collect(it))
    y = [f(xx) for xx in x]
    return FunctionEvaluations(x, y)
end

# Approximate the function using a uniform sampling over the bounding box
function approx(f::Function, bbox::Vector{<:Tuple}, c::Curvature, a::Algorithm;  kwargs...)
    
    defaults = (nsample=10, nseg=defaultseg()) 
    options = merge(defaults, kwargs)

    samples = max(options.nsample, 3*options.nseg)

    return approx(sample_uniform(f, bbox, samples), c, a; kwargs...)
end




#=
    Original interface starts here
=#

"""
    convex_linearization(x, z, optimizer; kwargs...)

Computes a piecewise linear function that approximates the measurements given by `x` and `z`.

# Arguments
- `method::Symbol:=fit`: the method used for approximation
- `dimensions::Integer:=2`: the number of dimensions of the function domain
- `nseg::Integer=5`: the number of segments to use 
- `nplanes::Integer=4`: the number of planes to use in 2D PWL functions
- `strict::Symbol=:none`: defines it is a general approximation, or an overestimation or underestimation
- `pen::Symbol=:l1`: the metric used to measure deviation


"""
function convex_linearization(x, z, optimizer; kwargs...)
    defaults = (;method=:fit, dimensions=1)
    options = merge(defaults, kwargs)

    method = options.method
    dimensions = options.dimensions

    if dimensions == 1
        @assert(length(x) == length(z))
        if method == :fit
            return convex_linearization_fit(x, z, optimizer; kwargs...)
        elseif method == :ipol
            return convex_linearization_ipol(x, z, optimizer; kwargs...)
        else
            error("Unrecognized method $method")
        end
    elseif dimensions >= 2
        if method == :fit
            return convex_ND_linearization_fit(x, z, optimizer; kwargs...)
        end    
    else
        error("Unrecognized number of dimensions $dimensions")
    end    
end

function conv_linear_big_M(x, z)
    N = length(x)
    cáµ‰Ë¢áµ— = (z[N] -z[N-1])/(x[N]-x[N-1])
    return  2 * cáµ‰Ë¢áµ— * (last(x) - first(x)) - maximum(z)
end

function conv_linear_big_M(x, z)
    N = length(x)
    cáµ‰Ë¢áµ— = (z[N] .- z[N-1]) ./ (x[N] .- x[N-1])
    return  2 .* cáµ‰Ë¢áµ— .* (last(x) .- first(x)) .- maximum(z)
end


#convex_linearization(x, z, optimizer; kwargs...)  = 
#    convex_linearization([xx for xx in x], [zz for zz in z], optimizer; kwargs...)

function convex_linearization_fit(x::Vector, z::Vector, optimizer; kwargs...)
  
    defaults = (nseg=defaultseg(), pen=defaultpenalty(), strict=false, start_origin=false, show_res=false)
    options = merge(defaults, kwargs)
  
    N = length(x)
    ğ’© = 1:N 
    ğ’¦ = 1:options.nseg
    
    Máµ‡â±áµ =  conv_linear_big_M(x,z)
    
    m = Model()
    @variable(m, ğ‘§Ì‚[ğ’©]) 
    @variable(m, ğ‘[ğ’¦])
    @variable(m, ğ‘‘[ğ’¦]) 
    @variable(m, ğ‘¢[ğ’©,ğ’¦], Bin)

    if options.pen == :l2 
        @objective(m, Min, sum((z[i] - ğ‘§Ì‚[i])^2 for i âˆˆ ğ’©))
    elseif options.pen == :max
        @variable(ğ‘¡, m)
        @objective(m, Min, ğ‘¡)
        for i âˆˆ ğ’©
            @constraint(m,  ğ‘¡ â‰¥ (z[i] - ğ‘§Ì‚[i]) )
            @constraint(m,  ğ‘¡ â‰¥ (ğ‘§Ì‚[i] - z[i]) )
        end
    elseif options.pen == :l1
        @variable(ğ‘¡, m, [ğ’©])
        @objective(m, Min, sum(ğ‘¡))
        for i âˆˆ ğ’©
            @constraint(m,  ğ‘¡[i] â‰¥ (z[i] - ğ‘§Ì‚[i]) )
            @constraint(m,  ğ‘¡[i] â‰¥ (ğ‘§Ì‚[i] - z[i]) )
        end
    else
        error("Unrecognized/unsupported penalty type $(options.pen)")
    end

    for i âˆˆ ğ’©, k âˆˆ ğ’¦ 
        @constraint(m, ğ‘§Ì‚[i] â‰¥ ğ‘[k] * x[i] + ğ‘‘[k])
        @constraint(m, ğ‘§Ì‚[i] â‰¤ ğ‘[k] * x[i] + ğ‘‘[k] + Máµ‡â±áµ * (1-ğ‘¢[i,k]))
    end

    if options.strict
        for i âˆˆ ğ’©, k âˆˆ ğ’¦ 
            @constraint(m, z[i] â‰¥ ğ‘[k] * x[i] + ğ‘‘[k])   
        end
    end

    if options.start_origin
        @constraint(m,ğ‘‘[1] == 0.0)
    end

    for i âˆˆ ğ’©
        @constraint(m, sum(ğ‘¢[i,k] for k âˆˆ ğ’¦) â‰¥ 1)
    end

    for k âˆˆ ğ’¦ 
        if k > 1
            @constraint(m, ğ‘[k-1] â‰¤ ğ‘[k])
        end
    end


    set_optimizer(m,optimizer)
    optimize!(m)

    if termination_status(m) != MOI.OPTIMAL
        error("Optimization failed")
    end

    if options.show_res
        println("Optimize succeed for $(options.pen)")
        val = objective_value(m)
        println("Objective value = $val")
    end
    
    ğ‘á´¼áµ–áµ— = value.(ğ‘)
    ğ‘‘á´¼áµ–áµ— = value.(ğ‘‘) 

    return PWLFunc{Convex,1}([Plane(Tuple(ğ‘á´¼áµ–áµ—[k]), ğ‘‘á´¼áµ–áµ—[k]) for k âˆˆ ğ’¦])
    # return ConvexPWLFunction([ğ‘á´¼áµ–áµ—[k] for k âˆˆ ğ’¦], [ğ‘‘á´¼áµ–áµ—[k] for k âˆˆ ğ’¦], minimum(x), maximum(x))
end

function convex_linearization(f::Function, xmin, xmax, optimizer; kwargs...)
    @assert(xmin < xmax)

    defaults = (nsample=10, nseg=defaultseg()) 
    options = merge(defaults, kwargs)

    samples = max(options.nsample, 3*options.nseg)

    step = (xmax - xmin) / samples
    x = [i for i in xmin:step:xmax]
    y = [f(xx) for xx in x]
    return convex_linearization(x, y, optimizer; kwargs...)
end

function concave_linearization(x, z, optimizer; kwargs...)
    if (size(x,2) < 2) && (length(first(x)) < 2)
        return ConcavePWLFunction(convex_linearization(x, -z, optimizer; kwargs...))
    else
        return ConcavePWLFunctionND(convex_linearization(x, -z, optimizer; kwargs...))
    end
end

function concave_linearization(f::Function, xmin, xmax, optimizer; kwargs...)
    if (size(x,2) < 2) && (length(first(X)) < 2)
        return ConcavePWLFunction(convex_linearization(x -> -f(x), xmin, xmax, optimizer; kwargs...))
    else
        return ConcavePWLFunctionND(convex_linearization(x -> -f(x), xmin, xmax, optimizer; kwargs...))
    end
end


function convexify(pwl::PWLFunction, optimizer)
    N = length(pwl.x)
    ğ’© = 1: N
    x = pwl.x
    z = pwl.z

    m = Model()

    Î´âº = @variable(m, [ğ’©], lower_bound=0)
    Î´â» = @variable(m, [ğ’©], lower_bound=0)

    @objective(m, Min, sum(Î´âº[i] + Î´â»[i] for i âˆˆ ğ’©))
    for i=2:N-1
        @constraint(m, (z[i] + Î´âº[i] - Î´â»[i] - z[i-1] - Î´âº[i-1] + Î´â»[i-1]) / 
            (x[i] -x[i-1]) <= (z[i+1] + Î´âº[i+1] - Î´â»[i+1] - z[i] - Î´âº[i] + Î´â»[i]) / (x[i+1] -x[i]))
    end

    set_optimizer(m,optimizer)
    optimize!(m)
    if termination_status(m) != MOI.OPTIMAL
        error("Optimization failed")
    end

    dp = value.(Î´âº)
    dn = value.(Î´â»)

    return ConvexPWLFunction(x, [z[i] + dp[i] - dn[i] for i âˆˆ ğ’©]) 
end

convexify(x, z, optimizer) =
    convexify(PWLFunction(x,z), optimizer)

function interpolatepw(x, z, optimizer; kwargs...)
    @assert(length(x) == length(z))

    defaults = (nseg=defaultseg(), pen=defaultpenalty())
    options = merge(defaults, kwargs)
   
    N = length(x)
    ğ’© = 1:N 

    # Find slopes
    c = [(z[j] -z[i]) / (x[j]-x[i])  for i âˆˆ ğ’©, j âˆˆ ğ’©]

    # Calculate penalties
    if options.pen == :l1
        p = [(i < j ? sum(abs(c[i,j] * (x[k] - x[i]) + z[i] - z[k]) for k âˆˆ i:j) : 0) for i âˆˆ ğ’©, j âˆˆ ğ’©]
    elseif options.pen == :l2
        p = [(i < j ? sum((c[i,j] * (x[k] - x[i]) + z[i] - z[k])^2 for k âˆˆ i:j) : 0) for i âˆˆ ğ’©, j âˆˆ ğ’©]
    elseif options.pen == :max
        p = [(i < j ? maximum(abs(c[i,j] * (x[k] - x[i]) + z[i] - z[k]) for k âˆˆ i:j) : 0) for i âˆˆ ğ’©, j âˆˆ ğ’©]
    else
        error("Unrecognized/unsupported penalty $(options.pen)")
    end
    
    m = Model()
    @variable(m, ğ‘¢[ğ’©,ğ’©], Bin)

    # Minimize total penalty
    @objective(m, Min, sum(p[i,j] * ğ‘¢[i,j] for i âˆˆ ğ’©, j âˆˆ ğ’©))

    # Number of line segments in interpolant
    @constraint(m, sum(ğ‘¢[i,j] for i âˆˆ ğ’©, j âˆˆ ğ’©) == options.nseg )

    # Only forward segments allowed
    for i âˆˆ ğ’©, j âˆˆ ğ’© 
        if i >= j 
            @constraint(m, ğ‘¢[i,j] == 0)
        end
    end 

    # Path modelling
    for j âˆˆ ğ’©
        @constraint(m, (j > 1 ? sum(ğ‘¢[i,j] for i âˆˆ ğ’©) : 1) == (j < N ? sum(ğ‘¢[j,i] for i âˆˆ ğ’© ) : 1))
    end

    set_optimizer(m,optimizer)
    optimize!(m)
    if termination_status(m) != MOI.OPTIMAL
        error("Optimization failed")
    end
    
    ğ‘¢á´¼áµ–áµ— = value.(m[:ğ‘¢])
    xá´¼áµ–áµ— = collect(x[i] for i âˆˆ ğ’©, j âˆˆ ğ’© if ğ‘¢á´¼áµ–áµ—[i,j] == 1)
    push!(xá´¼áµ–áµ—, x[N])
    zá´¼áµ–áµ— = collect(z[i] for i âˆˆ ğ’©, j âˆˆ ğ’© if ğ‘¢á´¼áµ–áµ—[i,j] == 1)
    push!(zá´¼áµ–áµ—, z[N])

    return PWLFunction(xá´¼áµ–áµ—, zá´¼áµ–áµ—)
end

convex_linearization_ipol(x, z, optimizer; kwargs...) = 
    convexify(interpolatepw(x, z, optimizer; kwargs...),optimizer)

function mat2tuples(x::Matrix)
    return collect(Tuple(x'[:,i]) for i in 1:size(x',2))
end
# mat2tuples2(x::Matrix) = ((Tuple(x[i,:]) for i in 1:size(x,1)))

function tuples2mat(ğ’«::Vector{Tuple{Float64, Float64}})
   return reduce(hcat, getindex.(ğ’«,i) for i in eachindex(ğ’«[1]))
end

function convex_ND_linearization_fit(x::Matrix{Float64}, z, optimizer; kwargs...)
    return convex_ND_linearization_fit(mat2tuples(x), z, optimizer; kwargs...)
end

linear_big_M(x, z) = 2 * maximum(z)

@deprecate convND_linear_big_M linear_big_M
function convND_linear_big_M(ğ’«::Vector{Tuple{Float64, Float64}}, z)
    return convND_linear_big_M(tuples2mat(ğ’«),z)
end

function convND_linear_big_M(x::Matrix{Float64}, z)
    ## TODO: calculate a tighter value for the big-M    
    return 2*maximum(z)
end

@deprecate convex_ND_linearization_fit approx
function convex_ND_linearization_fit(ğ’«, z, optimizer; kwargs...)

    defaults = (nsegs=defaultseg(), nplanes=defaultplanes(), pen=defaultpenalty2D(), strict=:none, show_res=false)
    options = merge(defaults, kwargs)

    záµ– = Dict(zip(ğ’«, z))
    ğ’¦ = 1:options.nplanes
    â„â‚š = 1:length(ğ’«[1])    

    Máµ‡â±áµ = linear_big_M(ğ’«, z) 

    m = Model()
    @variable(m, ğ‘§Ì‚[ğ’«])
    @variable(m, a[â„â‚š, ğ’¦])
    @variable(m, b[ğ’¦])

    @variable(m, ğ‘¢[ğ’«, ğ’¦], Bin)

    if options.pen == :l2 
        @objective(m, Min, sum((záµ–[p] - ğ‘§Ì‚[p])^2 for p âˆˆ ğ’«))
    elseif options.pen == :max
        ğ‘¡ = @variable(m)
        @objective(m, Min, ğ‘¡)
        for p âˆˆ ğ’«
            @constraint(m,  ğ‘¡ â‰¥ (záµ–[p] - ğ‘§Ì‚[p]) )
            @constraint(m,  ğ‘¡ â‰¥ (ğ‘§Ì‚[p] - záµ–[p]) )
        end
    elseif options.pen == :l1
        ğ‘¡ = @variable(m, [ğ’«])
        @objective(m, Min, sum(ğ‘¡))
        for p âˆˆ ğ’«
            @constraint(m,  ğ‘¡[p] â‰¥ (záµ–[p] - ğ‘§Ì‚[p]) )
            @constraint(m,  ğ‘¡[p] â‰¥ (ğ‘§Ì‚[p] - záµ–[p]) )
        end
    else
        error("Unrecognized/unsupported penalty type $(options.pen)")
    end
     
    for p âˆˆ ğ’«, k âˆˆ ğ’¦         
        @constraint(m, ğ‘§Ì‚[p] â‰¥ sum(a[j,k] * p[j] for j in â„â‚š) + b[k])
        @constraint(m, ğ‘§Ì‚[p] â‰¤ sum(a[j,k] * p[j] for j in â„â‚š) + b[k] + Máµ‡â±áµ * (1-ğ‘¢[p,k]))                
    end

    if options.strict == :above
        for p âˆˆ ğ’«, k âˆˆ ğ’¦ 
            @constraint(m, záµ–[p] â‰¥ sum(a[j,k] * p[j] for j in â„â‚š) + b[k]) 
        end
    elseif options.strict == :below
        for p âˆˆ ğ’«, k âˆˆ ğ’¦ 
            @constraint(m, záµ–[p] â‰¤ sum(a[j,k] * p[j] for j in â„â‚š) + b[k]) 
        end
    end
    
    for p âˆˆ ğ’«
        @constraint(m, sum(ğ‘¢[p,k] for k âˆˆ ğ’¦) â‰¥ 1)
    end    
    
    set_optimizer(m,optimizer)
    optimize!(m)

    if termination_status(m) != MOI.OPTIMAL
        error("Optimization failed")
    end

    if options.show_res
        println("Optimize succeed for $(options.pen)")
        val = objective_value(m)
        println("Objective value = $val")
    end   
    
    aá´¼áµ–áµ— = value.(a)
    bá´¼áµ–áµ— = value.(b)    
    
    # TODO: generalize for D (hard coded to 2 for now)
    return PWLFunc{Convex,2}([Plane(Tuple(aá´¼áµ–áµ—.data[:,k]), bá´¼áµ–áµ—[k]) for k âˆˆ ğ’¦])

    ##TODO: how to recover the data points from the coefficients?  Check package Polyhedra.    
end    

